{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wjGpDfzmfIdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ef4yJwmImo8G",
        "outputId": "ed2b3238-c528-4e13-9a1f-50221b355006"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: qiskit-terra==0.24.1 in /usr/local/lib/python3.11/dist-packages (0.24.1)\n",
            "Requirement already satisfied: qiskit-aer==0.12.0 in /usr/local/lib/python3.11/dist-packages (0.12.0)\n",
            "Requirement already satisfied: qiskit-ibmq-provider==0.20.2 in /usr/local/lib/python3.11/dist-packages (0.20.2)\n",
            "Requirement already satisfied: qiskit==0.43.1 in /usr/local/lib/python3.11/dist-packages (0.43.1)\n",
            "Requirement already satisfied: qiskit-machine-learning==0.6.1 in /usr/local/lib/python3.11/dist-packages (0.6.1)\n",
            "Requirement already satisfied: rustworkx>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-terra==0.24.1) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from qiskit-terra==0.24.1) (1.23.5)\n",
            "Requirement already satisfied: ply>=3.10 in /usr/local/lib/python3.11/dist-packages (from qiskit-terra==0.24.1) (3.11)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.11/dist-packages (from qiskit-terra==0.24.1) (5.9.5)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.11/dist-packages (from qiskit-terra==0.24.1) (1.15.3)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.11/dist-packages (from qiskit-terra==0.24.1) (1.13.1)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.11/dist-packages (from qiskit-terra==0.24.1) (0.3.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-terra==0.24.1) (2.9.0.post0)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-terra==0.24.1) (5.4.1)\n",
            "Requirement already satisfied: symengine<0.10,>=0.9 in /usr/local/lib/python3.11/dist-packages (from qiskit-terra==0.24.1) (0.9.2)\n",
            "Requirement already satisfied: requests>=2.19 in /usr/local/lib/python3.11/dist-packages (from qiskit-ibmq-provider==0.20.2) (2.32.3)\n",
            "Requirement already satisfied: requests-ntlm<=1.1.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-ibmq-provider==0.20.2) (1.1.0)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from qiskit-ibmq-provider==0.20.2) (2.5.0)\n",
            "Requirement already satisfied: websocket-client>=1.5.1 in /usr/local/lib/python3.11/dist-packages (from qiskit-ibmq-provider==0.20.2) (1.8.0)\n",
            "Requirement already satisfied: websockets>=10.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-ibmq-provider==0.20.2) (15.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-machine-learning==0.6.1) (1.6.1)\n",
            "Requirement already satisfied: fastdtw in /usr/local/lib/python3.11/dist-packages (from qiskit-machine-learning==0.6.1) (0.3.4)\n",
            "Requirement already satisfied: setuptools>=40.1.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-machine-learning==0.6.1) (75.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.0->qiskit-terra==0.24.1) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.20.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.20.2) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.20.2) (2025.7.14)\n",
            "Requirement already satisfied: ntlm-auth>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from requests-ntlm<=1.1.0->qiskit-ibmq-provider==0.20.2) (1.5.0)\n",
            "Requirement already satisfied: cryptography>=1.3 in /usr/local/lib/python3.11/dist-packages (from requests-ntlm<=1.1.0->qiskit-ibmq-provider==0.20.2) (43.0.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->qiskit-machine-learning==0.6.1) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->qiskit-machine-learning==0.6.1) (3.6.0)\n",
            "Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from stevedore>=3.0.0->qiskit-terra==0.24.1) (6.1.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.3->qiskit-terra==0.24.1) (1.3.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=1.3->requests-ntlm<=1.1.0->qiskit-ibmq-provider==0.20.2) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=1.3->requests-ntlm<=1.1.0->qiskit-ibmq-provider==0.20.2) (2.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install qiskit-terra==0.24.1 qiskit-aer==0.12.0 qiskit-ibmq-provider==0.20.2 qiskit==0.43.1 qiskit-machine-learning==0.6.1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is implemented on 22/07/2025 by shanika\n",
        "Breast-Lesions-USG | A Curated Benchmark Dataset for Ultrasound Based Breast Lesion Analysis\n",
        "Dataset: https://www.cancerimagingarchive.net/collection/breast-lesions-usg/#citations_%22Download_link%22"
      ],
      "metadata": {
        "id": "ngpEr6WZm0gU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install genomic-benchmarks"
      ],
      "metadata": {
        "id": "5e2PCyZ51XGw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5ecb774-c6d1-4114-cf68-9cf4500fc4bb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: genomic-benchmarks in /usr/local/lib/python3.11/dist-packages (0.0.9)\n",
            "Requirement already satisfied: biopython>=1.79 in /usr/local/lib/python3.11/dist-packages (from genomic-benchmarks) (1.85)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from genomic-benchmarks) (2.32.3)\n",
            "Requirement already satisfied: pip>=20.0.1 in /usr/local/lib/python3.11/dist-packages (from genomic-benchmarks) (24.1.2)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from genomic-benchmarks) (1.23.5)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from genomic-benchmarks) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.11/dist-packages (from genomic-benchmarks) (4.67.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from genomic-benchmarks) (6.0.2)\n",
            "Requirement already satisfied: gdown>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from genomic-benchmarks) (5.2.0)\n",
            "Requirement already satisfied: yarl in /usr/local/lib/python3.11/dist-packages (from genomic-benchmarks) (1.20.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=4.2.0->genomic-benchmarks) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown>=4.2.0->genomic-benchmarks) (3.18.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->genomic-benchmarks) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->genomic-benchmarks) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->genomic-benchmarks) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->genomic-benchmarks) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->genomic-benchmarks) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->genomic-benchmarks) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->genomic-benchmarks) (2025.7.14)\n",
            "Requirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.11/dist-packages (from yarl->genomic-benchmarks) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from yarl->genomic-benchmarks) (0.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.4->genomic-benchmarks) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.2.0->genomic-benchmarks) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.2.0->genomic-benchmarks) (4.14.1)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.2.0->genomic-benchmarks) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "from datetime import datetime\n",
        "import time\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# ─── 0. Capture the start timestamp ────────────────────────────────────────────\n",
        "start_ts   = datetime.now()\n",
        "# Format as “DD_MM_YYYY_HHMMSS” (no colons, so filesystem‑safe)\n",
        "start_str  = start_ts.strftime(\"%d_%m_%Y_%H%M%S\")\n",
        "\n",
        "# ─── 1. Experiment configuration ───────────────────────────────────────────────\n",
        "'''\n",
        "num_epochs = 10 #50\n",
        "max_train_iterations = 100\n",
        "samples_per_epoch=100 #10\n",
        "word_size = 40\n",
        "use_teleportation             = True   # or False/True\n",
        "use_noise =True\n",
        "'''\n",
        "num_epochs = 10 #50\n",
        "max_train_iterations = 100\n",
        "samples_per_epoch=100 #10\n",
        "word_size = 40\n",
        "use_teleportation             = True   # or False/True\n",
        "use_noise =True\n",
        "\n",
        "\n",
        "num_clients = 5 #8 test with teleport\n",
        "num_federated_layers = 10\n",
        "num_deep_unfolding_iterations = 5\n",
        "initial_learning_rate = 0.15\n",
        "meta_learning_rate=1e-4\n",
        "initial_perturbation = 0.15\n",
        "momentum = 0.95\n",
        "gradient_moving_avg = 0\n",
        "\n",
        "# Define federated learning with accuracy tracking\n",
        "num_features = 5\n",
        "global_model_weights, global_model_accuracy = {}, []\n",
        "clients_train_accuracies, clients_test_accuracies = [], []\n",
        "round_times = []\n",
        "overall_start = time.time()\n",
        "\n",
        "\n",
        "# ─── 2. Helper to make floats filesystem‑safe (“0.15” → “0p15”) ─────────────────\n",
        "def fmt(x: float) -> str:\n",
        "    return str(x).replace('.', 'p')\n",
        "\n",
        "# ─── 3. Build the hyperparameter string ───────────────────────────────────────\n",
        "param_str = (\n",
        "    f\"clients{num_clients}\"\n",
        "    f\"_layers{num_federated_layers}\"\n",
        "    f\"_du{num_deep_unfolding_iterations}\"\n",
        "    f\"_lr{fmt(initial_learning_rate)}\"\n",
        "    f\"_pert{fmt(initial_perturbation)}\"\n",
        ")\n",
        "\n",
        "# ─── 4. Date stamp and Teleport flag ───────────────────────────────────────────\n",
        "date_str    = datetime.now().strftime(\"%d_%m_%Y\")               # e.g. \"22_04_2025\"\n",
        "teleport_pl = \"Teleport\" if use_teleportation else \"NoTeleport\"\n",
        "noise = \"WithNoise\" if use_noise else \"NoNoise\"\n",
        "\n",
        "# ─── 5. Assemble filenames for each artifact ─────────────────────────────────\n",
        "drive_root = \"/content/drive/MyDrive\"\n",
        "\n",
        "\n",
        "#  a) Best‑client CSV\n",
        "best_client_csv_file = os.path.join(\n",
        "    drive_root,\n",
        "    f\"Secured_DuQFL_Genome_nonIID_Best_Client_{date_str}_{teleport_pl}_{noise}_{param_str}.csv\"\n",
        ")\n",
        "\n",
        "#  b) Global‑accuracy CSV\n",
        "global_csv_file = os.path.join(\n",
        "    drive_root,\n",
        "    f\"Secured_DuQFL_Genome_nonIID_Global_{date_str}_{teleport_pl}_{noise}_{param_str}.csv\"\n",
        ")\n",
        "\n",
        "#  c) Local CSV\n",
        "csv_file = os.path.join(\n",
        "    drive_root,\n",
        "    f\"Secured_DuQFL_Genome_nonIID_Local_{date_str}_{teleport_pl}_{noise}_{param_str}.csv\"\n",
        ")\n",
        "\n",
        "validation_csv_file = os.path.join(\n",
        "    drive_root,\n",
        "    f\"Secured_DuQFL_Genome_nonIID_validation_Loss_{date_str}_{teleport_pl}_{noise}_{param_str}.csv\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "6sZXbHLSPRK1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Qiskit core components\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
        "from qiskit_aer import Aer\n",
        "from qiskit.primitives import BackendSampler\n",
        "\n",
        "# Qiskit Machine Learning components\n",
        "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
        "from qiskit_machine_learning.algorithms.classifiers import VQC, NeuralNetworkClassifier\n",
        "\n",
        "# Qiskit algorithms and utilities\n",
        "from qiskit.algorithms.optimizers import COBYLA, SPSA\n",
        "from qiskit.utils import algorithm_globals\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "algorithm_globals.random_seed = 42\n",
        "\n",
        "# Scikit-learn utilities\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n"
      ],
      "metadata": {
        "id": "s1AQONncnk14"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Preprocessing"
      ],
      "metadata": {
        "id": "yg2UVo9yPxD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from genomic_benchmarks.dataset_getters.pytorch_datasets import DemoHumanOrWorm\n",
        "# Set random seed for reproducibility using algorithm_globals\n",
        "algorithm_globals.random_seed = 42  # Set seed globally\n",
        "\n",
        "\n",
        "test_set = DemoHumanOrWorm(split='test', version=0)\n",
        "train_set = DemoHumanOrWorm(split='train', version=0)\n",
        "\n",
        "data_set = train_set\n",
        "# data_set = train_set + test_set\n",
        "len(data_set)\n",
        "\n",
        "\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "word_combinations = defaultdict(int)\n",
        "iteration = 1\n",
        "for text, _ in data_set:\n",
        "    for i in range(len(text)):\n",
        "        word = text[i:i+word_size]\n",
        "        if word_combinations.get(word) is None:\n",
        "          word_combinations[word] = iteration\n",
        "          iteration += 1\n",
        "\n",
        "\n",
        "\n",
        "print(\"First sample int the data_set variable: \")\n",
        "print(data_set[0])\n",
        "\n",
        "print(\"\\nFirst 5 samples in the word_combinations dict.\")\n",
        "for key, value in list(word_combinations.items())[:5]:\n",
        "    print(key, value)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "# Preprocess the training set\n",
        "np_data_set = []\n",
        "for i in range(len(data_set)):\n",
        "    sequence, label = data_set[i]\n",
        "    sequence = sequence.strip()  # Remove any leading/trailing whitespace\n",
        "    words = [sequence[i:i + word_size] for i in range(0, len(sequence), word_size)]  # Split the sequence into 4-letter words\n",
        "    int_sequence = np.array([word_combinations[word] for word in words])\n",
        "    data_point = {'sequence': int_sequence, 'label': label}\n",
        "    np_data_set.append(data_point)\n",
        "\n",
        "\n",
        "print(\"First 5 samples of encoded data:\")\n",
        "np_data_set[:5]\n",
        "\n",
        "\n",
        "np.random.shuffle(np_data_set)\n",
        "print(\"First 5 samples of encoded shuffled data:\")\n",
        "np_data_set[:5]\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "sequences = np.array([item['sequence'] for item in np_data_set])\n",
        "sequences = np.vstack(sequences)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "sequences_scaled = scaler.fit_transform(sequences)\n",
        "\n",
        "for i, item in enumerate(np_data_set):\n",
        "    item['sequence'] = sequences_scaled[i]\n",
        "\n",
        "print(\"First 5 samples of scaled encoded shuffled data:\")\n",
        "np_data_set[:5]\n",
        "\n"
      ],
      "metadata": {
        "id": "VIRAqKDsokWi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50414249-fd4a-4eaf-f3fa-12ed4a5b5180"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/genomic_benchmarks/utils/datasets.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First sample int the data_set variable: \n",
            "('CCAGGTTCAAGCGATTCTCCTGCCTCGGCCTCCCTAGTAGCTGGGATTACAGATGTGTGCCACCACACTAGGCTAATTTTTGTATTTTTAGTAGAGATGGGGTTTCGCCATGTTGGCCAGGCTGGTCTCGAACTCCTGACCTCAGGTGATCCACCCAACTCGGCCTTCCAAAGTGCTGGGATTACAGGCGTGAGCCACTG', 0)\n",
            "\n",
            "First 5 samples in the word_combinations dict.\n",
            "CCAGGTTCAAGCGATTCTCCTGCCTCGGCCTCCCTAGTAG 1\n",
            "CAGGTTCAAGCGATTCTCCTGCCTCGGCCTCCCTAGTAGC 2\n",
            "AGGTTCAAGCGATTCTCCTGCCTCGGCCTCCCTAGTAGCT 3\n",
            "GGTTCAAGCGATTCTCCTGCCTCGGCCTCCCTAGTAGCTG 4\n",
            "GTTCAAGCGATTCTCCTGCCTCGGCCTCCCTAGTAGCTGG 5\n",
            "First 5 samples of encoded data:\n",
            "First 5 samples of encoded shuffled data:\n",
            "First 5 samples of scaled encoded shuffled data:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'sequence': array([0.12578583, 0.12578583, 0.12578583, 0.12578583, 0.12578583]),\n",
              "  'label': 0},\n",
              " {'sequence': array([0.44185776, 0.44185776, 0.44185776, 0.44185776, 0.44185776]),\n",
              "  'label': 0},\n",
              " {'sequence': array([0.22576272, 0.22576272, 0.22576272, 0.22576272, 0.22576272]),\n",
              "  'label': 0},\n",
              " {'sequence': array([0.20594389, 0.20594389, 0.20594389, 0.20594389, 0.20594389]),\n",
              "  'label': 0},\n",
              " {'sequence': array([0.8251445, 0.8251445, 0.8251445, 0.8251445, 0.8251445]),\n",
              "  'label': 1}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Split train, test validaton data"
      ],
      "metadata": {
        "id": "AwUR6OznPrEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "global_seed = 42  # You can choose any integer value for the seed\n",
        "\n",
        "# 5) Split into federated train vs central validation\n",
        "train_frac = 0.9\n",
        "train_list, central_val = train_test_split(\n",
        "    np_data_set, train_size=train_frac, random_state=global_seed,\n",
        "    stratify=[d['label'] for d in np_data_set]\n",
        ")\n",
        "X_val = np.stack([d['sequence'] for d in central_val])\n",
        "y_val = np.array([d['label'] for d in central_val])\n",
        "print(f\"Train for federated: {len(train_list)}, central val: {len(central_val)}\")\n",
        "\n",
        "\n",
        "np_train_data = train_list[:5000]\n",
        "np_test_data = np_data_set[-200:]\n",
        "\n",
        "print(f\"Length of sample train data for FL: {len(np_train_data)}\")\n",
        "print(f\"Length of sample test data for FL: {len(np_test_data)}\")\n",
        "\n",
        "test_sequences = [data_point[\"sequence\"] for data_point in np_test_data]\n",
        "test_labels = [data_point[\"label\"] for data_point in np_test_data]\n",
        "test_sequences = np.array(test_sequences)\n",
        "test_labels = np.array(test_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1ftIupGP4G_",
        "outputId": "bfeb24d0-1670-4cb0-a38a-ed074e4bfb2d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train for federated: 67500, central val: 7500\n",
            "Length of sample train data for FL: 5000\n",
            "Length of sample test data for FL: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "class Client:\n",
        "    def __init__(self, data, test_data):  # Add test_data to __init__\n",
        "        self.data = data\n",
        "        self.test_data = test_data  # Store test_data as an attribute\n",
        "        self.models = []\n",
        "        self.train_scores = []\n",
        "        self.test_scores = []\n",
        "        self.primary_model = None\n",
        "\n",
        "\n",
        "\n",
        "def split_dataset_quantity_non_iid_binary(dataset, num_clients, num_epochs, samples_per_epoch, non_iid_ratio=0.5, quantity_variation=0.2):\n",
        "    \"\"\"\n",
        "    Splits a binary-labeled dataset into non-IID partitions among clients, varying the quantity of data.\n",
        "\n",
        "    Args:\n",
        "        dataset: list of dicts with 'features' and 'label'.\n",
        "        num_clients: total number of clients.\n",
        "        num_epochs: number of epochs.\n",
        "        samples_per_epoch: base samples assigned to each client per epoch.\n",
        "        non_iid_ratio: how skewed (0.5 = balanced, 1.0 = completely biased to one label).\n",
        "        quantity_variation: how much to vary the quantity of data per client (0.0 = no variation, 1.0 = up to double the base samples).\n",
        "    \"\"\"\n",
        "    label_0 = [sample for sample in dataset if sample[\"label\"] == 0]\n",
        "    label_1 = [sample for sample in dataset if sample[\"label\"] == 1]\n",
        "    random.shuffle(label_0)\n",
        "    random.shuffle(label_1)\n",
        "\n",
        "    client_label_0_counts = []\n",
        "    client_label_1_counts = []\n",
        "\n",
        "    # Create Client objects and assign data to them\n",
        "    clients_data = []\n",
        "\n",
        "    for client_id in range(num_clients):\n",
        "        client_data = []\n",
        "        selected_label_0 = []\n",
        "        selected_label_1 = []\n",
        "        # Track the number of labels assigned to each client\n",
        "        client_label_0_count = 0\n",
        "        client_label_1_count = 0\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            # Vary the quantity of data per client\n",
        "            epoch_samples = int(samples_per_epoch * (1 + random.uniform(-quantity_variation, quantity_variation)))\n",
        "\n",
        "            if client_id % 2 == 0:  # Even client gets a higher proportion of label 0\n",
        "                num_label_0 = int(epoch_samples * non_iid_ratio)\n",
        "                num_label_1 = epoch_samples - num_label_0\n",
        "            else:  # Odd client gets a higher proportion of label 1\n",
        "                num_label_1 = int(epoch_samples * non_iid_ratio)\n",
        "                num_label_0 = epoch_samples - num_label_1\n",
        "\n",
        "            # Select the required number of samples for each label\n",
        "            selected_label_0 = label_0[:num_label_0]\n",
        "            selected_label_1 = label_1[:num_label_1]\n",
        "\n",
        "            # Update the remaining dataset\n",
        "            label_0 = label_0[num_label_0:]\n",
        "            label_1 = label_1[num_label_1:]\n",
        "\n",
        "            # Update counts for label distribution\n",
        "            client_label_0_count += num_label_0\n",
        "            client_label_1_count += num_label_1\n",
        "\n",
        "            # Append data for the current epoch to the client's data\n",
        "            client_data.append(selected_label_0 + selected_label_1);\n",
        "\n",
        "        # Store the final counts for the client\n",
        "        client_label_0_counts.append(client_label_0_count)\n",
        "        client_label_1_counts.append(client_label_1_count)\n",
        "\n",
        "        clients_data.append(client_data)  # Append client's data for all epochs\n",
        "\n",
        "\n",
        "\n",
        "    # Plotting the results\n",
        "    clients = list(range(num_clients))\n",
        "    width = 0.35  # the width of the bars\n",
        "    x = np.arange(len(clients))  # the label locations\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    rects1 = ax.bar(x - width/2, client_label_0_counts, width, label='Label 0', color='blue')\n",
        "    rects2 = ax.bar(x + width/2, client_label_1_counts, width, label='Label 1', color='orange')\n",
        "\n",
        "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "    ax.set_ylabel('Number of Samples')\n",
        "    ax.set_title(f'Distribution of Label 0 and Label 1 Across Clients (Non-IID Split)')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(clients)\n",
        "    ax.legend()\n",
        "\n",
        "    fig.tight_layout()\n",
        "\n",
        "    plt.show()\n",
        "    return clients_data # Return the clients data\n",
        "\n",
        "# Example usage\n",
        "#dataset = [{'features': [random.random(), random.random()], 'label': random.choice([0, 1])} for _ in range(1000)]\n",
        "clients=[]# Initialize the list of Client objects\n",
        "client_data_list =split_dataset_quantity_non_iid_binary(\n",
        "  dataset=np_train_data,\n",
        "  num_clients=5,\n",
        "  num_epochs=10,\n",
        "  samples_per_epoch=50,\n",
        "  non_iid_ratio=0.8,  # 0.5, 0, 1.0\n",
        "  quantity_variation=0.5) #\n",
        "\n",
        "\n",
        "for client_data in client_data_list:\n",
        "    client = Client(client_data, test_data=np_test_data)\n",
        "    clients.append(client)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "syuzNstGP8EK",
        "outputId": "82c5005d-2d74-471c-bea6-4e9686378211"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Local Deep Unfolding Step"
      ],
      "metadata": {
        "id": "SR6kGJfTQD7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Callback function to capture the loss values\n",
        "objective_func_vals = []  # Global list to store loss values\n",
        "learning_rates = []\n",
        "perturbations = []\n",
        "\n",
        "\n",
        "\n",
        "import os  # For handling directories\n",
        "\n",
        "# Define the directory to save the plots\n",
        "output_dir = \"federated_round_plots\"\n",
        "os.makedirs(output_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
        "# Initialize a global variable to track the round number\n",
        "current_round = 1\n",
        "\n",
        "# Callback for visualization, gradient smoothing, and learning rate adjustment in deep unfolding\n",
        "def deep_unfolding_learning_rate_adjustment(parameters, obj_func_eval, gradients=None,round_number=0):\n",
        "    global gradient_moving_avg, learning_rates, perturbations,current_round\n",
        "\n",
        "    clear_output(wait=True)\n",
        "\n",
        "    # Save the objective function value for visualization\n",
        "    objective_func_vals.append(obj_func_eval)\n",
        "\n",
        "    # If gradients are provided, smooth the gradient using momentum\n",
        "    if gradients is not None:\n",
        "        gradient_moving_avg = momentum * gradient_moving_avg + (1 - momentum) * gradients  # Apply moving average\n",
        "        delta_lr = 0.05 * gradient_moving_avg  # Adjust learning rate based on the smoothed gradient\n",
        "        delta_perturbation = 0.1 * gradient_moving_avg  # Adjust perturbation based on the same gradient\n",
        "    else:\n",
        "        delta_lr = 0  # No gradient info available in this iteration\n",
        "        delta_perturbation = 0\n",
        "\n",
        "    # Update learning rate and perturbation\n",
        "    if len(learning_rates) > 0:\n",
        "        new_lr = max(0.001, learning_rates[-1] + delta_lr)  # Ensure learning rate is positive and non-zero\n",
        "        new_perturbation = max(0.001, perturbations[-1] + delta_perturbation)  # Ensure perturbation is positive\n",
        "    else:\n",
        "        new_lr = initial_learning_rate\n",
        "        new_perturbation = initial_perturbation\n",
        "\n",
        "    learning_rates.append(new_lr)\n",
        "    perturbations.append(new_perturbation)\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # Visualization of learning rate and perturbation\n",
        "    plt.figure(figsize=(10, 12))  # Adjust figure size for better spacing\n",
        "\n",
        "    # Plot Objective Function Value\n",
        "    plt.subplot(3, 1, 1)\n",
        "    plt.plot(range(len(objective_func_vals)), objective_func_vals, label=\"Objective Function Value\", color='blue')\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"Objective Function Value\")\n",
        "    plt.title(\"Objective Function Over Iterations\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.grid(True)  # Add grid for better readability\n",
        "\n",
        "    # Plot Learning Rate\n",
        "    plt.subplot(3, 1, 2)\n",
        "    plt.plot(range(len(learning_rates)), learning_rates, label=\"Learning Rate\", color='green')\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"Learning Rate\")\n",
        "    plt.title(\"Learning Rate Over Iterations\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot Perturbation\n",
        "    plt.subplot(3, 1, 3)\n",
        "    plt.plot(range(len(perturbations)), perturbations, label=\"Perturbation\", color='red')\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"Perturbation\")\n",
        "    plt.title(\"Perturbation Over Iterations\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout(pad=3.0)  # Add padding between subplots\n",
        "    # Save the plot after each federated round\n",
        "    #plot_filename = os.path.join(output_dir, f\"federated_round_{current_round}.png\")\n",
        "    #plt.savefig(plot_filename)  # Save the figure\n",
        "    #plt.show()\n",
        "    plt.close()  # Close the plot to free memory\n",
        "\n",
        "    # Increment the round number for the next call\n",
        "    current_round += 1\n",
        "\n",
        "\n",
        "# Define the SPSA callback to capture gradients and update learning rate and perturbation dynamically\n",
        "def spsa_callback(nfev, parameters, obj_func_eval, stepsize, accept):\n",
        "    # Assuming `stepsize` contains gradient information or its approximation\n",
        "    gradients = stepsize\n",
        "    deep_unfolding_learning_rate_adjustment(parameters, obj_func_eval, gradients)\n",
        "\n",
        "# Custom SPSA optimizer with learnable learning rate and perturbation\n",
        "class LearnableLRPerturbationSPSA(SPSA):\n",
        "    def __init__(self, initial_lr=1e-4, initial_perturbation=0.01, lr_alpha=0.1, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.lr = initial_lr  # Initial learning rate\n",
        "        self.perturbation = initial_perturbation  # Initial perturbation\n",
        "        self.lr_alpha = lr_alpha  # Learning rate and perturbation update speed\n",
        "\n",
        "    def _update_learning_rate_and_perturbation(self, gradient, obj_func_eval):\n",
        "        \"\"\"\n",
        "        Update both learning rate and perturbation based on gradient and objective function evaluation.\n",
        "        The learning rate increases if the objective function improves and decreases otherwise.\n",
        "        \"\"\"\n",
        "        # Use the gradient sign to determine if we should increase or decrease\n",
        "        grad_lr = np.sign(np.mean(gradient))  # Average gradient sign across parameters\n",
        "\n",
        "        if grad_lr > 0:  # Objective function is improving\n",
        "            self.lr += self.lr_alpha * abs(grad_lr)  # Increase learning rate\n",
        "            self.perturbation += self.lr_alpha * abs(grad_lr)  # Increase perturbation\n",
        "        else:  # Objective function is getting worse\n",
        "            self.lr -= self.lr_alpha * abs(grad_lr)  # Decrease learning rate\n",
        "            self.perturbation -= self.lr_alpha * abs(grad_lr)  # Decrease perturbation\n",
        "\n",
        "        # Ensure both learning rate and perturbation are positive\n",
        "        self.lr = max(0.001, self.lr)\n",
        "        self.perturbation = max(0.001, self.perturbation)\n",
        "\n",
        "    def step(self, gradient, obj_func_eval):\n",
        "        \"\"\"\n",
        "        Perform optimization step for both parameters, learning rate, and perturbation.\n",
        "        Use the objective function evaluation to dynamically adjust learning rate and perturbation.\n",
        "        \"\"\"\n",
        "        self._update_learning_rate_and_perturbation(gradient, obj_func_eval)\n",
        "        return super().step(gradient)  # Perform SPSA step for parameters\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reset the optimizer state (learning rates, perturbations, and gradient moving averages) for the next round.\n",
        "        \"\"\"\n",
        "        self.lr = initial_learning_rate\n",
        "        self.perturbation = initial_perturbation\n",
        "        self.gradient_moving_avg = 0  # Reset the moving average of the gradient\n",
        "        learning_rates.clear()  # Reset the learning rates history\n",
        "        perturbations.clear()  # Reset the perturbations history\n",
        "        objective_func_vals.clear()  # Clear the objective function history"
      ],
      "metadata": {
        "id": "dRKq8hdzP_fN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "=== Secure DUQFL Integration with ML-KEM ==="
      ],
      "metadata": {
        "id": "EVPFjlhMaSCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kyber_py pycryptodome\n",
        "from kyber_py.ml_kem import ML_KEM_512\n",
        "from Crypto.Cipher import AES\n",
        "from Crypto.Util.Padding import pad, unpad\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pQ48f_maTwa",
        "outputId": "77cb8928-36a7-455b-fe7c-bd127fb33897"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kyber_py in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.11/dist-packages (3.23.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === SERVER SIDE SETUP ===\n",
        "# Generate server key pair (once)\n",
        "ek_server, dk_server = ML_KEM_512.keygen()"
      ],
      "metadata": {
        "id": "7bwweQ8naXsn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Crypto.Random import get_random_bytes"
      ],
      "metadata": {
        "id": "GUY6vC-iaaB5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simulate_unauthorized_decryption(ciphertext, capsule):\n",
        "    try:\n",
        "        # Attempt to decapsulate with incorrect key\n",
        "        K_fake = ML_KEM_512.decaps(dk_fake_adversary, capsule)\n",
        "        cipher = AES.new(K_fake[:16], AES.MODE_ECB)\n",
        "        decrypted = unpad(cipher.decrypt(ciphertext), 16)\n",
        "        print(\"[Attack Simulation] Decryption succeeded (Unexpected).\")\n",
        "        return decrypted\n",
        "    except Exception as e:\n",
        "        print(\"[Attack Simulation] Decryption failed (As Expected):\", str(e))\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "luYrNDqhacN2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create optimizer with learnable learning rate and perturbation\n",
        "spsa_optimizer = LearnableLRPerturbationSPSA(\n",
        "      maxiter=25, learning_rate=initial_learning_rate, perturbation=initial_perturbation, callback=spsa_callback, lr_alpha=0.01\n",
        ")\n",
        "\n",
        "\n",
        "#======================================================\n",
        "# Initialize QNN model\n",
        "def initialize_model(num_features,initial_params):\n",
        "    feature_map = ZZFeatureMap(feature_dimension=num_features, reps=2)\n",
        "    ansatz = RealAmplitudes(num_qubits=num_features, reps=3)\n",
        "    qc = feature_map.compose(ansatz)\n",
        "\n",
        "    # Create optimizer with learnable learning rate and perturbation\n",
        "    #spsa_optimizer = LearnableLRPerturbationSPSA(\n",
        "     #maxiter=25, learning_rate=initial_learning_rate, perturbation=initial_perturbation, callback=spsa_callback, lr_alpha=0.01\n",
        "#)\n",
        "    global spsa_optimizer\n",
        "    def parity(x):\n",
        "        return \"{:b}\".format(x).count(\"1\") % 2\n",
        "\n",
        "    sampler_qnn = SamplerQNN(\n",
        "        circuit=qc,\n",
        "        interpret=parity,\n",
        "        output_shape=2,\n",
        "        input_params=feature_map.parameters,\n",
        "        weight_params=ansatz.parameters\n",
        "    )\n",
        "\n",
        "\n",
        "    # Define the neural network classifier\n",
        "    qnn_classifier = NeuralNetworkClassifier(\n",
        "      neural_network=sampler_qnn,\n",
        "      optimizer=spsa_optimizer,\n",
        "      loss='squared_error',\n",
        "      initial_point=initial_params,  # Initialize with the starting parameters\n",
        ")\n",
        "\n",
        "\n",
        "    return qnn_classifier\n",
        "\n",
        "#=====================================================\n",
        "#=====================================================\n",
        "from google.colab import drive\n",
        "import csv\n",
        "# Step 1: Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Define the save path in Google Drive\n",
        "csv_file = csv_file\n",
        "\n",
        "# Step 3: Define headers for the CSV\n",
        "headers = [\"Federated Round\", \"Client Number\", \"Iteration\", \"Objective Function Value\",\n",
        "           \"Training Accuracy\", \"Test Accuracy\", \"Learning Rate\", \"Perturbation\",\"raw_entropy\", \"encrypted_entropy\",\"Unauthorized Decryption\", \"Fake Accuracy\", \"Encryption Status\"]\n",
        "\n",
        "# Open the CSV file and write headers if it's the first time writing to the file\n",
        "with open(csv_file, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(headers)\n",
        "\n",
        "# Example of saving results for each federated round and client\n",
        "def save_results(federated_round, client_id, iteration, obj_func_val, train_acc, test_acc, learning_rate, perturbation,raw_entropy, encrypted_entropy, unauthorized_status, fake_acc, encryption_status):\n",
        "    with open(csv_file, mode='a', newline='') as file:  # Open file in append mode\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([federated_round, client_id, iteration, obj_func_val, train_acc, test_acc, learning_rate, perturbation,raw_entropy, encrypted_entropy,unauthorized_status, fake_acc, encryption_status])\n",
        "#=====================================================\n",
        "#=====================================================\n",
        "\n",
        "# 7) Validation loss helper\n",
        "def compute_validation_loss(model, X, y):\n",
        "    \"\"\"\n",
        "    Compute the average cross-entropy loss on (X,y) using the QNN's output probabilities.\n",
        "    Falls back to a direct forward call if predict_proba is unavailable.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Preferred: scikit-like API if available\n",
        "        proba = model.predict_proba(X)\n",
        "    except AttributeError:\n",
        "        # Fallback: extract weights and call the QNN forward method\n",
        "        weights = model._fit_result.x\n",
        "        proba = model._neural_network.forward(X, weights)\n",
        "    return log_loss(y, proba)\n",
        "\n",
        "\n",
        "\n",
        "#==================================\n",
        "#Apply encryption===\n",
        "\n",
        "encrypted_model_storage = {}\n",
        "dk_fake_adversary = get_random_bytes(1632)\n",
        "\n",
        "#Measure entropy of transmitted parameters\n",
        "from scipy.stats import entropy\n",
        "from collections import Counter\n",
        "\n",
        "def compute_byte_entropy(byte_array):\n",
        "    counter = Counter(byte_array)\n",
        "    probabilities = [count / len(byte_array) for count in counter.values()]\n",
        "    return entropy(probabilities, base=2)\n",
        "\n",
        "\n",
        "#====================================================\n",
        "# Federated learning loop per client\n",
        "def train_qnn_model(client_data, client_test_data, model=None, client_id=None, layer=None,enable_encryption=True):\n",
        "\n",
        "    global learning_rates, perturbations, objective_func_vals\n",
        "    global encrypted_model_storage  # Fixes the scope\n",
        "    print(\"Client Data Structure:\")  # Add this line to print the structure\n",
        "    print(client_data)                # This line prints the actual data\n",
        "    print(type(client_data))           # This line prints the data type\n",
        "    #num_features = client_data[0][\"sequence\"].shape[0]\n",
        "\n",
        "    #initial_params = np.random.rand(RealAmplitudes(client_data.shape[1], reps=4).num_parameters)  # Initialize params\n",
        "    initial_params = np.random.rand(RealAmplitudes(len(client_data[0][\"sequence\"]), reps=3).num_parameters)\n",
        "\n",
        "    if model is None:\n",
        "        model = initialize_model(num_features, initial_params)\n",
        "\n",
        "    train_sequences = np.array([data_point[\"sequence\"] for data_point in client_data])\n",
        "    train_labels = np.array([data_point[\"label\"] for data_point in client_data])\n",
        "    test_sequences = np.array([data_point[\"sequence\"] for data_point in client_test_data])\n",
        "    test_labels = np.array([data_point[\"label\"] for data_point in client_test_data])\n",
        "\n",
        "    train_accuracies, test_accuracies, total_time = [], [], 0\n",
        "\n",
        "    train_accuracies = []\n",
        "    test_accuracies = []\n",
        "\n",
        "    # Deep Unfolding with multiple iterations\n",
        "    # Continue training with learned weights and adjust learning rate based on performance and gradients.\n",
        "    total_time = 0\n",
        "    current_params = initial_params  # Start with the initial parameters\n",
        "\n",
        "    for i in range(num_deep_unfolding_iterations):\n",
        "        print(\"\\n\")\n",
        "        print(f\"Deep Unfolding Iteration {i+1}/{num_deep_unfolding_iterations}\")\n",
        "        start_time = time.time()\n",
        "        model.fit(train_sequences, train_labels)\n",
        "        end_time = time.time()\n",
        "        total_time += end_time - start_time\n",
        "\n",
        "        # After training, retrieve the updated parameters from the optimizer\n",
        "        current_params = model.weights\n",
        "        print(f\"Trained parameters after iteration {i+1}: {current_params}\")\n",
        "\n",
        "        # Store final weights and learning rate for next round\n",
        "        final_learning_rate = learning_rates[-1]\n",
        "        final_perturbation = perturbations[-1]\n",
        "\n",
        "        # Evaluate the model performance\n",
        "        train_accuracy = model.score(train_sequences, train_labels)\n",
        "        test_accuracy = model.score(test_sequences, test_labels)\n",
        "\n",
        "        # Store accuracies for future reference\n",
        "        train_accuracies.append(train_accuracy)\n",
        "        test_accuracies.append(test_accuracy)\n",
        "\n",
        "        #======Apply encryption using ML_KE===============\n",
        "\n",
        "        model_bytes = np.array(current_params).tobytes()\n",
        "\n",
        "        if enable_encryption:\n",
        "            try:\n",
        "                K, c = ML_KEM_512.encaps(ek_server)\n",
        "                cipher = AES.new(K[:16], AES.MODE_ECB)\n",
        "                ciphertext = cipher.encrypt(pad(model_bytes, 16))\n",
        "                encryption_status = \"HPKE Secure\"\n",
        "            except Exception as e:\n",
        "                print(\"[Encryption Failed]:\", str(e))\n",
        "                ciphertext, c, encryption_status = b'', None, \"Encryption Error\"\n",
        "        else:\n",
        "            ciphertext = model_bytes\n",
        "            c = None\n",
        "            encryption_status = \"No Encryption\"\n",
        "\n",
        "        encrypted_model_storage[client_id] = (ciphertext, c)\n",
        "        tampered_bytes = simulate_unauthorized_decryption(ciphertext, c) if enable_encryption else ciphertext\n",
        "\n",
        "        if tampered_bytes:\n",
        "            try:\n",
        "                tampered_weights = np.frombuffer(tampered_bytes, dtype=np.float64)\n",
        "                fake_model = initialize_model(num_features, tampered_weights)\n",
        "                fake_accuracy = fake_model.score(test_sequences, test_labels)\n",
        "                unauthorized_status = \"Success\"\n",
        "            except Exception as e:\n",
        "                fake_accuracy = 0.0\n",
        "                print(\"[Fake Model Reconstruction Failed]:\", str(e))\n",
        "                unauthorized_status = \"Success (Corrupted)\"\n",
        "        else:\n",
        "            fake_accuracy, unauthorized_status = 0.0, \"Fail\"\n",
        "\n",
        "        raw_entropy = compute_byte_entropy(model_bytes)\n",
        "        encrypted_entropy = compute_byte_entropy(ciphertext)\n",
        "\n",
        "        print(f\"[Security] Raw Entropy: {raw_entropy:.2f}, Encrypted Entropy: {encrypted_entropy:.2f}\")\n",
        "        print(f\"[Security] Unauthorized Access: {unauthorized_status}, Fake Accuracy: {fake_accuracy:.2f}\")\n",
        "        print(f\"[Security] Mode: {encryption_status}\")\n",
        "\n",
        "\n",
        "        # Write the results to the CSV file\n",
        "        save_results(\n",
        "            layer, client_id, i + 1,\n",
        "            objective_func_vals[-1],\n",
        "            train_accuracy * 100,\n",
        "            test_accuracy * 100,\n",
        "            final_learning_rate,\n",
        "            final_perturbation,\n",
        "            raw_entropy,\n",
        "            encrypted_entropy,\n",
        "            unauthorized_status,\n",
        "            fake_accuracy * 100,\n",
        "            encryption_status  # <-- NEW\n",
        "        )\n",
        "\n",
        "        #with open(csv_file, mode='a', newline='') as file:\n",
        "          #writer = csv.writer(file)\n",
        "         #writer.writerow([i+1, objective_func_vals[-1], train_accuracy * 100, test_accuracy * 100, final_learning_rate, final_perturbation])\n",
        "\n",
        "        # Update the learning rate for the next iteration based on gradients from SPSA\n",
        "        spsa_optimizer.learning_rate = learning_rates[-1]\n",
        "        model.initial_point = current_params\n",
        "\n",
        "        # Log performance\n",
        "        print(f\"Iteration {i+1} - Learning Rate: {final_learning_rate:.6f}\")\n",
        "        print(f\"Iteration {i+1} - Training Accuracy: {train_accuracy:.2f}\")\n",
        "        print(f\"Iteration {i+1} - Test Accuracy: {test_accuracy :.2f}\")\n",
        "\n",
        "    return model, train_accuracy, test_accuracy, total_time\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_e3S0LHQIkR",
        "outputId": "24029926-f86d-48fc-887e-75ee1e86e73c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step to empty the CSV file before starting a new run\n",
        "def clear_csv_file():\n",
        "    \"\"\"\n",
        "    Clears the CSV file by overwriting it with headers or leaving it blank.\n",
        "    \"\"\"\n",
        "    with open(csv_file, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        # Uncomment the next line to write headers for the new run\n",
        "        writer.writerow(headers)\n",
        "        # Leave it blank if you prefer not to include headers\n",
        "        # pass\n"
      ],
      "metadata": {
        "id": "pyYCXCNXQg9E"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_global_accuracy(model, val_sequences, val_labels):\n",
        "    \"\"\"\n",
        "    Evaluate the accuracy of the given model on the test dataset.\n",
        "\n",
        "    Parameters:\n",
        "        model: The trained model to evaluate.\n",
        "        num_features: The number of features in each data sample.\n",
        "        test_sequences: A list or array of test input data (features).\n",
        "        test_labels: A list or array of true labels corresponding to the test data.\n",
        "\n",
        "    Returns:\n",
        "        float: The accuracy of the model as a percentage.\n",
        "    \"\"\"\n",
        "    global_accuracy = model.score(val_sequences, val_labels)\n",
        "    return global_accuracy\n"
      ],
      "metadata": {
        "id": "V3zDZVVwQiLS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(model, test_sequences, test_labels):\n",
        "    \"\"\"\n",
        "    Evaluate the accuracy of the given model on the test dataset.\n",
        "\n",
        "    Parameters:\n",
        "        model: The trained model to evaluate.\n",
        "        num_features: The number of features in each data sample.\n",
        "        test_sequences: A list or array of test input data (features).\n",
        "        test_labels: A list or array of true labels corresponding to the test data.\n",
        "\n",
        "    Returns:\n",
        "        float: The accuracy of the model as a percentage.\n",
        "    \"\"\"\n",
        "    test_accuracy = model.score(test_sequences, test_labels)\n",
        "    return test_accuracy\n",
        "\n",
        "# Function to extract numerical values of parameters\n",
        "def extract_param_values(model):\n",
        "    #param_values = []\n",
        "    # Loop through each parameter in the circuit and get its bound value\n",
        "    # Retrieve the circuit from the neural network\n",
        "    circuit = model.neural_network.circuit\n",
        "\n",
        "    # Extract the parameter values bound to the circuit\n",
        "    # Use enumerate to get both index and parameter\n",
        "    param_values = {param: circuit.parameters[i] for i, param in enumerate(circuit.parameters)}\n",
        "    return param_values\n",
        "#def set_param_values(model, param_values):\n",
        "    # Retrieve the circuit from the neural network\n",
        "    #circuit = model.neural_network.circuit\n",
        "\n",
        "    # Use assign_parameters to update the parameter values\n",
        "    #circuit.assign_parameters(param_values, inplace=True)\n",
        "# Function to set numerical values of parameters back into the circuit\n",
        "def set_param_values(model, param_values):\n",
        "    # Assign the averaged parameter values back to the circuit\n",
        "    parameter_dict = {param: value for param, value in zip(model.neural_network.circuit.parameters, param_values)}\n",
        "    model.neural_network.circuit.assign_parameters(parameter_dict)\n",
        "\n",
        "\n",
        "# Manually average the numerical values of the parameters across clients\n",
        "def manual_average_weights(epoch_weights):\n",
        "    # Initialize a list to store the summed weights (initialize with zeros)\n",
        "    num_weights = len(epoch_weights[0])  # Number of weights in the model\n",
        "    num_clients = len(epoch_weights)  # Number of clients\n",
        "\n",
        "    # Initialize sum of weights to zero (assuming NumPy array or list of weights)\n",
        "    summed_weights = np.zeros(num_weights)\n",
        "\n",
        "    # Sum the weights from all clients\n",
        "    for client_weights in epoch_weights:\n",
        "        summed_weights += np.array(client_weights)\n",
        "\n",
        "    # Compute the average by dividing the summed weights by the number of clients\n",
        "    average_weights = summed_weights / num_clients\n",
        "\n",
        "    return average_weights\n",
        "\n",
        "def create_model_with_weights(weights):\n",
        "    initial_params = np.random.rand(RealAmplitudes(num_features, reps=3).num_parameters)\n",
        "    model = initialize_model(num_features,weights)\n",
        "    #set_param_values(model, weights)  # Assign global weights to the model\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "Me8bfinwQkCf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to save accuracies to CSV\n",
        "def save_accuracies_to_csv(global_accuracies, clients_train_accuracies, clients_test_accuracies, filename='accuracies.csv'):\n",
        "    with open(filename, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "\n",
        "        # Write the header row\n",
        "        header = ['Epoch', 'Global Accuracy']\n",
        "        for i in range(len(clients_train_accuracies[0])):  # Assuming all clients have the same number of records\n",
        "            header.append(f'Client {i} Train Accuracy')\n",
        "            header.append(f'Client {i} Test Accuracy')\n",
        "        writer.writerow(header)\n",
        "\n",
        "        # Write the accuracy data for each epoch\n",
        "        for epoch in range(len(global_accuracies)):\n",
        "            row = [epoch, global_accuracies[epoch]]  # Start with epoch and global accuracy\n",
        "            for client_index in range(len(clients_train_accuracies[epoch])):\n",
        "                row.append(clients_train_accuracies[epoch][client_index])  # Add train accuracy for client\n",
        "                row.append(clients_test_accuracies[epoch][client_index])   # Add test accuracy for client\n",
        "            writer.writerow(row)\n"
      ],
      "metadata": {
        "id": "ykQywZoCQmEF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start Implementing Telepotation"
      ],
      "metadata": {
        "id": "EN8KQXdtXgFN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iF7FcO4gXi9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit import QuantumCircuit, Aer, execute\n",
        "from qiskit.visualization import plot_histogram\n",
        "from qiskit.providers.aer.noise import NoiseModel, errors\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def teleport_parameter(val, show_histogram=False, use_noise=False):\n",
        "    \"\"\"\n",
        "    Simulated teleportation of a single parameter with an option to add noise.\n",
        "\n",
        "    Args:\n",
        "        val (float): The parameter value to teleport.\n",
        "        show_histogram (bool): If True, display the histogram of measurement outcomes.\n",
        "        use_noise (bool): If True, execute the circuit with an added noise model.\n",
        "\n",
        "    Returns:\n",
        "        float: The parameter value (assumed to be perfectly transmitted ideally).\n",
        "    \"\"\"\n",
        "    qc = QuantumCircuit(3, 2)\n",
        "\n",
        "    # --- Encode the parameter on qubit 0 ---\n",
        "    qc.rx(val, 0)\n",
        "\n",
        "    # --- Prepare an entangled pair ---\n",
        "    qc.h(1)\n",
        "    qc.cx(1, 2)\n",
        "\n",
        "    # --- Bell-State Measurement ---\n",
        "    qc.cx(0, 1)\n",
        "    qc.h(0)\n",
        "    qc.measure([0, 1], [0, 1])\n",
        "\n",
        "    # --- Conditional Corrections on qubit 2 ---\n",
        "    qc.cx(1, 2).c_if(qc.cregs[0], 1)\n",
        "    qc.cz(0, 2).c_if(qc.cregs[0], 2)\n",
        "\n",
        "    backend = Aer.get_backend('qasm_simulator')\n",
        "\n",
        "    # Define a noise model\n",
        "    noise_model = None\n",
        "    if use_noise:\n",
        "      # define matching errors ,Define separate error objects for your single‑ and two‑qubit gates.\n",
        "      #Attach each error only to gates of the matching size.\n",
        "       #1% depolarizing on single‑qubit gates\n",
        "        one_q_error = errors.depolarizing_error(0.001, 1)\n",
        "        # e.g. 2% depolarizing on two‑qubit gates ( can choose a different rate)\n",
        "        two_q_error = errors.depolarizing_error(0.005, 2)\n",
        "\n",
        "        noise_model = NoiseModel()\n",
        "        noise_model.add_all_qubit_quantum_error(one_q_error, ['rx', 'h'])\n",
        "        noise_model.add_all_qubit_quantum_error(two_q_error, ['cx'])\n",
        "\n",
        "        # Add a depolarizing error to single-qubit gates with probability 1%\n",
        "        #error = errors.depolarizing_error(0.01, 1)\n",
        "        #oise_model.add_all_qubit_quantum_error(error, ['rx', 'h', 'cx'])\n",
        "\n",
        "    result = execute(qc, backend, shots=1024, noise_model=noise_model).result()\n",
        "    counts = result.get_counts(qc)\n",
        "\n",
        "    if show_histogram:\n",
        "        plot_histogram(counts)\n",
        "        plt.show()\n",
        "\n",
        "    # In an ideal simulation, we assume perfect transmission\n",
        "    # If noise is applied,  can compare the output statistics.\n",
        "    return val\n",
        "\n",
        "def teleport_parameters(params, show_histogram=False, use_noise=False):\n",
        "    \"\"\"\n",
        "    Applies the teleportation process to a vector of parameters.\n",
        "\n",
        "    Each parameter is processed individually. The optional noise parameter\n",
        "    allows you to simulate realistic transmission errors.\n",
        "\n",
        "    Args:\n",
        "        params (array-like): A vector of parameters.\n",
        "        show_histogram (bool): If True, display the histogram for each parameter.\n",
        "        use_noise (bool): If True, simulate noise in the circuit execution.\n",
        "\n",
        "    Returns:\n",
        "        np.array: The array of transmitted parameter values.\n",
        "    \"\"\"\n",
        "    teleported = [teleport_parameter(p, show_histogram, use_noise) for p in params]\n",
        "    return np.array(teleported)\n"
      ],
      "metadata": {
        "id": "nIei2q4nXjVH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Global Aggregation"
      ],
      "metadata": {
        "id": "7Xsoxk1aZqax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decrypt_and_assign_weights(model, client_id):\n",
        "    ciphertext, c = encrypted_model_storage[client_id]\n",
        "    K_prime = ML_KEM_512.decaps(dk_server, c)\n",
        "    cipher = AES.new(K_prime[:16], AES.MODE_ECB)\n",
        "    decrypted_bytes = unpad(cipher.decrypt(ciphertext), 16)\n",
        "    decryptedweights = np.frombuffer(decrypted_bytes, dtype=np.float64)\n",
        "\n",
        "    # === Verification Step ===\n",
        "    original_weights = model.weights\n",
        "    if np.allclose(decryptedweights, original_weights, atol=1e-6):\n",
        "        print(f\"[Verification] Decrypted weights match original weights for Client {client_id}\")\n",
        "    else:\n",
        "        print(f\"[Verification] Decrypted weights DO NOT match original weights for Client {client_id}\")\n",
        "        print(\"Original Weights (first 5):\", original_weights[:5])\n",
        "        print(\"Decrypted Weights (first 5):\", decryptedweights[:5])\n",
        "    return decryptedweights\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "i8I9s9YfZthh"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a global list to track global loss\n",
        "global_loss_per_round = []\n",
        "\n",
        "from sklearn.metrics import log_loss # Import log_loss here\n",
        "\n",
        "# Display information about the data assigned to each client\n",
        "for idx, client in enumerate(clients):\n",
        "    print(f\"Client {idx + 1}:\")\n",
        "    print(f\"  Train data epochs: {len(client.data)}\")\n",
        "    print(f\"  Test data samples: {len(client.test_data)}\")\n",
        "\n",
        "    # Accessing the number of features in a sequence\n",
        "    if client.data:\n",
        "        num_features=client.data[0][0]['sequence'].shape[0]  # Access first data point of epoch 0\n",
        "        #num_features = client.data[0]['sequence'].shape[0]\n",
        "        print(f\"  Number of features in a sequence: {num_features}\")\n",
        "\n",
        "def reset_state():\n",
        "    # Reset the objective value, learning rate, and perturbation after each client\n",
        "    global objective_func_vals, learning_rates, perturbations\n",
        "    objective_func_vals = []  # Reset objective values\n",
        "    learning_rates = []  # Reset learning rates\n",
        "    perturbations = []  # Reset perturbations\n",
        "# Function to reset callback graph state after each round\n",
        "def reset_callback_graph():\n",
        "    global gradient_moving_avg, learning_rates, perturbations\n",
        "\n",
        "    # Reset the state variables to start fresh for the next round\n",
        "    gradient_moving_avg = np.zeros_like(gradient_moving_avg)  # Reset gradient moving average\n",
        "    learning_rates = [initial_learning_rate]  # Reset learning rates list to initial value\n",
        "    perturbations = [initial_perturbation]  # Reset perturbations list to initial value\n",
        "import csv\n",
        "\n",
        "# Path to store the best client's data\n",
        "#best_client_csv_file = '/content/drive/My Drive/Best_Client_DQFL_Genome_IID_22_04_2025_Teleport.csv'\n",
        "\n",
        "\n",
        "\n",
        "# Update CSV headers to include round time\n",
        "best_headers = [\"Federated Round\", \"Client Number\", \"Round Duration (s)\"]\n",
        "with open(best_client_csv_file, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(best_headers)\n",
        "\n",
        "# Function to update the best client data\n",
        "def save_best_client_results(federated_round, best_client_index, round_duration):\n",
        "    with open(best_client_csv_file, mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([federated_round,\n",
        "                         best_client_index,\n",
        "                         f\"{round_duration:.4f}\"])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Clear the CSV file for a new run\n",
        "clear_csv_file()\n",
        "\n",
        "\n",
        "# --- Before starting  federated loop: initialize the CSV with a header ---\n",
        "with open(validation_csv_file, mode='w', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(['Round', 'Central Validation Loss'])\n",
        "\n",
        "validation_loss_per_round = []\n",
        "\n",
        "# Wrap the epoch loop with tqdm\n",
        "for epoch in tqdm(range(num_federated_layers), desc=\"Training Progress\", leave =True):\n",
        "    round_start = time.time()\n",
        "\n",
        "    global_model_weights[epoch] = []\n",
        "    epoch_train_accuracies, epoch_test_accuracies = [], []\n",
        "    best_client_index = -1\n",
        "    best_client_accuracy = -1\n",
        "    best_client_model = None\n",
        "    print(\"\\n\")\n",
        "    print(f\"Fed_Epoch: {epoch}\")\n",
        "    round_losses = []  # Track individual client losses for this round\n",
        "\n",
        "    for index, client in enumerate(clients):\n",
        "        print(\"\\n\")\n",
        "        print(f\"Fed_Epoch {epoch}, Client {index + 1}:\")\n",
        "        reset_state()\n",
        "\n",
        "        try:\n",
        "            # Ensure you're using the correct index for data\n",
        "            current_data = client.data[epoch]  # This assumes data is structured in epochs\n",
        "            print(f\"Training data for epoch {epoch}: {len(current_data)}\")\n",
        "        except IndexError:\n",
        "            print(f\"No data available for epoch {epoch} for Client {index + 1}\")\n",
        "            continue  # Skip this client for the current epoch\n",
        "\n",
        "        model, train_score, test_score, train_time = train_qnn_model(\n",
        "            client.data[epoch],\n",
        "            client.test_data,\n",
        "            client_id=index,\n",
        "            layer=epoch,enable_encryption=True\n",
        "   )\n",
        "\n",
        "\n",
        "        epoch_train_accuracies.append(train_score)\n",
        "        epoch_test_accuracies.append(test_score)\n",
        "\n",
        "        # Fetch the client's loss (assumes train_qnn_model returns it)\n",
        "        #current_loss = objective_func_vals[-1]  # Fetch latest loss\n",
        "        #round_losses.append(current_loss)\n",
        "        # Calculate global loss for the current round as the average of client losses\n",
        "\n",
        "\n",
        "        # Check if this client has the best accuracy so far\n",
        "        if test_score > best_client_accuracy:\n",
        "            best_client_accuracy = test_score\n",
        "            best_client_index = index\n",
        "            best_client_model = model  # Directly store the best client's model\n",
        "\n",
        "    #global_loss = sum(round_losses) / len(round_losses)\n",
        "    #global_loss_per_round.append(global_loss)  # Store the global loss\n",
        "\n",
        "    #print(f\"Global Loss for Round {epoch}: {global_loss}\")\n",
        "\n",
        "    round_duration = time.time() - round_start\n",
        "    round_times.append(round_duration)\n",
        "    print(f\"Time for Round {epoch}: {round_duration:.2f} s\")\n",
        "\n",
        "    #Save best client *and* round duration to CSV\n",
        "    save_best_client_results(epoch, best_client_index, round_duration)\n",
        "  # Save to best client CSV\n",
        "    print(f\"Best client for epoch {epoch} is Client {best_client_index + 1} with test accuracy {best_client_accuracy:.2f}\")\n",
        "\n",
        "    #-----------------------------------------------------------------Teleportation------------------------------------------------\n",
        "\n",
        "    ## --- Quantum Teleportation-based Model Update Transfer ---\n",
        "    # Extract, teleport, and update the global model parameters.\n",
        "    # Choose quantum update transmission scheme:\n",
        "    #use_teleportation = True  # Set to False to simulate pure entanglement transfer\n",
        "\n",
        "\n",
        "    # Treat the best client's model as the global model for the next round\n",
        "    #Extract\n",
        "    global_model = best_client_model\n",
        "    #global_params = global_model.weights\n",
        "\n",
        "    print(\"Available keys in encrypted_model_storage:\", encrypted_model_storage.keys())\n",
        "    print(\"Requested key:\", best_client_index)\n",
        "\n",
        "    global_params = decrypt_and_assign_weights(global_model, best_client_index)\n",
        "    #global_params = global_model.weight\n",
        "\n",
        "\n",
        "    #Teleport\n",
        "    if use_teleportation:\n",
        "        updated_params = teleport_parameters(global_params, show_histogram=False, use_noise=False)\n",
        "    else:\n",
        "        updated_params = global_params\n",
        "    global_model.initial_point = updated_params\n",
        "\n",
        "    # Update all clients with the global model\n",
        "    for index, client in enumerate(clients):\n",
        "        client.primary_model = global_model\n",
        "\n",
        "    # Evaluate the global model on the new test data\n",
        "    global_accuracy = get_accuracy(global_model, test_sequences, test_labels)\n",
        "    global_model_accuracy.append(global_accuracy)\n",
        "\n",
        "    clients_train_accuracies.append(epoch_train_accuracies)\n",
        "    clients_test_accuracies.append(epoch_test_accuracies)\n",
        "\n",
        "    print(f\"Global Model Accuracy in Epoch {epoch}: {global_accuracy:.2f}\")\n",
        "    print(\"----------------------------------------------------------\")\n",
        "\n",
        "\n",
        "    # evaluate central validation\n",
        "    L_val = compute_validation_loss(global_model, X_val, y_val)\n",
        "    validation_loss_per_round.append(L_val)\n",
        "    print(f\"After round {epoch}, central val loss = {L_val:.4f}\\n\")\n",
        "\n",
        "    # --- Append the latest validation loss to the CSV ---\n",
        "    with open(validation_csv_file, mode='a', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([epoch, L_val])\n",
        "\n",
        "\n",
        "\n",
        "    # Save results for the current iteration of the client in the federated round\n",
        "    from google.colab import drive\n",
        "\n",
        "    # Step 1: Mount Google Drive\n",
        "    #drive.mount('/content/drive')\n",
        "\n",
        "    # Step 2: Define the save path in Google Drive\n",
        "    #save_path = '/content/drive/MyDrive/DQFL_Genome_IID_Global__22_04_2025_Teleport.csv'\n",
        "\n",
        "\n",
        "    # Save accuracies to CSV after each epoch (or at the end of all epochs)\n",
        "    save_accuracies_to_csv(global_model_accuracy, clients_train_accuracies, clients_test_accuracies, filename=global_csv_file)\n",
        "    # After each round, reset callback state to prepare for the next round\n",
        "    reset_callback_graph()\n",
        "    print(f\"File saved to {global_csv_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "zSUJrvNbXnrY",
        "outputId": "d8b55803-4c28-4d48-a632-4f1637c30598"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:   0%|          | 0/10 [02:07<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-22-2831827169.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mcontinue\u001b[0m  \u001b[0;31m# Skip this client for the current epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         model, train_score, test_score, train_time = train_qnn_model(\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-13-2837754544.py\u001b[0m in \u001b[0;36mtrain_qnn_model\u001b[0;34m(client_data, client_test_data, model, client_id, layer, enable_encryption)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Deep Unfolding Iteration {i+1}/{num_deep_unfolding_iterations}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mtotal_time\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit_machine_learning/algorithms/trainable_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit_machine_learning/algorithms/classifiers/neural_network_classifier.py\u001b[0m in \u001b[0;36m_fit_internal\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mfunction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_minimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_create_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mObjectiveFunction\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit_machine_learning/algorithms/trainable_model.py\u001b[0m in \u001b[0;36m_minimize\u001b[0;34m(self, function)\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[1;32m    294\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             optimizer_result = self._optimizer.minimize(\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mfun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                 \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_point\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit/algorithms/optimizers/spsa.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, fun, x0, jac, bounds)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0miteration_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;31m# compute update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m             \u001b[0mfx_estimate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlse_solver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0;31m# trust region\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit/algorithms/optimizers/spsa.py\u001b[0m in \u001b[0;36m_compute_update\u001b[0;34m(self, loss, x, k, eps, lse_solver)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;31m# accumulate the number of samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m         \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhessian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_point_estimate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;31m# precondition gradient with inverse Hessian, if specified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit/algorithms/optimizers/spsa.py\u001b[0m in \u001b[0;36m_point_estimate\u001b[0;34m(self, loss, x, eps, num_samples)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mdelta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeltas2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecond_order\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             value_sample, gradient_sample, hessian_sample = self._point_sample(\n\u001b[0m\u001b[1;32m    467\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit/algorithms/optimizers/spsa.py\u001b[0m in \u001b[0;36m_point_sample\u001b[0;34m(self, loss, x, eps, delta1, delta2)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;31m# batch evaluate the points (if possible)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_batch_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_evals_grouped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0mplus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit/algorithms/optimizers/spsa.py\u001b[0m in \u001b[0;36m_batch_evaluate\u001b[0;34m(function, points, max_evals_grouped, unpack_points)\u001b[0m\n\u001b[1;32m    726\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmax_evals_grouped\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmax_evals_grouped\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;31m# support functions with multiple arguments where the points are given in a tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         return [\n\u001b[0m\u001b[1;32m    729\u001b[0m             \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpoint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         ]\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit/algorithms/optimizers/spsa.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;31m# support functions with multiple arguments where the points are given in a tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m         return [\n\u001b[0;32m--> 729\u001b[0;31m             \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpoint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m         ]\n\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit_machine_learning/algorithms/objective_functions.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;31m# probabilities is of shape (N, num_outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_neural_network_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mnum_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_neural_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit_machine_learning/algorithms/objective_functions.py\u001b[0m in \u001b[0;36m_neural_network_forward\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m    100\u001b[0m         ):\n\u001b[1;32m    101\u001b[0m             \u001b[0;31m# compute forward and cache the results for re-use in backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_forward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_neural_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0;31m# a copy avoids keeping a reference to the same array, so we are sure we have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;31m# different arrays on the next iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit_machine_learning/neural_networks/neural_network.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_data, weights)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mweights_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0moutput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_forward_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit_machine_learning/neural_networks/sampler_qnn.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, input_data, weights)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_circuit\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameter_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mQiskitMachineLearningError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sampler job failed.\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit/primitives/primitive_job.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;34m\"\"\"Return the results of the job.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_submitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcancel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize QNN model for each client at the start of the Federated Round"
      ],
      "metadata": {
        "id": "hx5OufyExCao"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Results in Drive for Local Training for Each Client"
      ],
      "metadata": {
        "id": "FaIqdkd8xIyk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement Teleportation"
      ],
      "metadata": {
        "id": "1zr2KXW8zjef"
      }
    }
  ]
}